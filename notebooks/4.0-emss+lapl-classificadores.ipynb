{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c39639a-0773-40ba-b49b-2177768ed2bf",
   "metadata": {},
   "source": [
    "# Escolha do modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a45d0-da86-4e8b-a319-65e25433d8ae",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8e0b7b1-3a80-4c3c-9328-d7d200205495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from hydra import initialize, compose\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba27669-8a66-4ab1-a73b-916bf7094b71",
   "metadata": {},
   "source": [
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43adb8fa-ed4b-40d3-a708-ec99a7dfd26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../config/\"):\n",
    "    cfg = compose(config_name='main')\n",
    "    \n",
    "df = pd.read_csv(f\"../{cfg.data.processed}\")\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, normalizacao):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "\n",
    "    best_params = model.best_params_\n",
    "\n",
    "    return {\n",
    "        'Normalization': normalizacao,\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        **best_params\n",
    "    }\n",
    "\n",
    "def evaluate_results(grids, X_test, y_test, normalizacao, dataframe):\n",
    "    \n",
    "    grid_dict = {\n",
    "        0: 'Logistic Regression', \n",
    "        1: 'Support Vector Machines',\n",
    "        2: 'Multinomial Naive Bayes',\n",
    "        3: 'KNeighbors Classifier',\n",
    "        4: 'Decision Tree',\n",
    "        5: 'Random Forest'\n",
    "    }\n",
    "\n",
    "    results_list = []\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    for i, model in enumerate(grids):\n",
    "        \n",
    "        results = evaluate_model(model, X_test, y_test, normalizacao)\n",
    "        results_list.append(results)\n",
    "    \n",
    "        \n",
    "    results_df = pd.DataFrame(results_list, index=grid_dict.values())\n",
    "        \n",
    "    return pd.concat([dataframe, results_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90389ce1-5312-463e-b775-8d39c07d3fa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cleaned text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6d42-f2db-4abf-958f-b1d93c8f0a5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Binary, Word Count and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "916910c4-3294-4625-b93d-5fcd9fd41913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.encoded_sentiment\n",
    "\n",
    "X = df.cleaned_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'LR__C': param_range\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [\"english\"],\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dec57580-cef7-4bee-91f7-51616a1518ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a7de8278-048d-4910-b636-66c15c70f83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Cleaned Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6cbbf-aa4d-4025-a82e-aa7a7d5d092f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4d7276fe-bce7-4c70-9a4a-309b95de51da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df1.encoded_sentiment\n",
    "\n",
    "X = df1.cleaned_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'LR__C': param_range,\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "84c63e4f-f569-429f-b71e-0313c7b52ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ae3e19e7-dd9d-4e6f-8490-8003bacb3cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Cleaned Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89102976-2603-4270-8965-e710da6b4dea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stematized text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea9129-b910-4673-b82c-43f736c19297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Binary, Word Count and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e92e0aee-a21c-4016-9129-51b7b98fa975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.encoded_sentiment\n",
    "\n",
    "X = df.stematized_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'LR__C': param_range\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [\"english\"],\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b88d54c8-4d1e-476e-ac79-5d57b8f6fec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "96ef3605-a230-46db-940f-962a473784c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Stematized Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528fde1-7814-4aa4-8d46-26b100b6ae8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "967456df-9b9a-4b68-bd17-0ecabdc041c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.encoded_sentiment\n",
    "\n",
    "X = df.stematized_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'LR__C': param_range,\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3598fc62-19a8-4cdd-a537-3d6d180475b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a92566c7-5655-4a01-9f3a-67e98bb85a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Stematized Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc084a6-59fc-4f0b-8dc1-6d29f1d8639c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lemmatized text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9829b21-f31a-445f-92bf-2961760388e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Binary, Word Count and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "178ce126-0060-44e0-88a7-2f35edc589f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.encoded_sentiment\n",
    "\n",
    "X = df.lemmatized_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'LR__C': param_range\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [\"english\"],\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'count_vec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'count_vec__binary': [True, False],\n",
    "    'count_vec__stop_words': [None, \"english\"],\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5a3d6d34-047b-4c9a-bedf-82b3b3e9c9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "56da8b42-13d5-4285-8e30-af354e248f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Lemmatized Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9275d-800c-42b9-9ac4-f52cf06dc95a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6c253b22-510f-445e-b7bd-d0e87e9e98ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.encoded_sentiment\n",
    "\n",
    "X = df.lemmatized_text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_range = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "\n",
    "lr_param_grid = [{\n",
    "    'LR__C': param_range,\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "svm_param_grid = [{\n",
    "    'SVC__C': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "nb_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "knn_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "dt_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "rf_param_grid = [{\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}]\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=pipeline_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "svm_grid_search = GridSearchCV(estimator=pipeline_svm,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=pipeline_nb,\n",
    "        param_grid=nb_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=pipeline_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=pipeline_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=pipeline_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3)\n",
    "\n",
    "grids = [lr_grid_search, svm_grid_search, nb_grid_search, knn_grid_search, dt_grid_search, rf_grid_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3012f1a1-1a59-48bb-a442-2ff0ca8b5998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "091d615f-d986-45ca-8e80-0e3ef872a2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = evaluate_results(grids, X_test, y_test, 'Lemmatized Text', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe71e3-da15-4436-81a3-99e93e39b72c",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "943f8fe5-b03c-4807-ad82-f036427d7589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalization</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LR__C</th>\n",
       "      <th>count_vec__binary</th>\n",
       "      <th>count_vec__ngram_range</th>\n",
       "      <th>count_vec__stop_words</th>\n",
       "      <th>SVC__C</th>\n",
       "      <th>tfidf__ngram_range</th>\n",
       "      <th>tfidf__stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.827765</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.813534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.825046</td>\n",
       "      <td>0.822884</td>\n",
       "      <td>0.825046</td>\n",
       "      <td>0.813627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.798024</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.798526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.723757</td>\n",
       "      <td>0.700185</td>\n",
       "      <td>0.723757</td>\n",
       "      <td>0.668487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.791885</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.787444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.810313</td>\n",
       "      <td>0.823593</td>\n",
       "      <td>0.810313</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.771639</td>\n",
       "      <td>0.792641</td>\n",
       "      <td>0.771639</td>\n",
       "      <td>0.727352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.790767</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.724450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.749540</td>\n",
       "      <td>0.796832</td>\n",
       "      <td>0.749540</td>\n",
       "      <td>0.681934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.758748</td>\n",
       "      <td>0.746820</td>\n",
       "      <td>0.758748</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.720074</td>\n",
       "      <td>0.727385</td>\n",
       "      <td>0.720074</td>\n",
       "      <td>0.723251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Cleaned Text</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>0.775389</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.845525</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.832728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.842081</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.831540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.811962</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.812060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.712707</td>\n",
       "      <td>0.678187</td>\n",
       "      <td>0.712707</td>\n",
       "      <td>0.662052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.838074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.807480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.811901</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.758078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.814893</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.756948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.800104</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.688522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>0.753502</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>0.755488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.818222</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.818832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.823509</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.799137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.843037</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.827700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.793621</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.790906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.718232</td>\n",
       "      <td>0.688574</td>\n",
       "      <td>0.718232</td>\n",
       "      <td>0.664438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.797957</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.794194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.821363</td>\n",
       "      <td>0.837467</td>\n",
       "      <td>0.821363</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.782689</td>\n",
       "      <td>0.803408</td>\n",
       "      <td>0.782689</td>\n",
       "      <td>0.744373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.801663</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.741581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.800104</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.688522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors Classifier</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.758439</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.758999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.793448</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.794999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.792461</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.768120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Normalization  Test Accuracy  Precision    Recall  \\\n",
       "Logistic Regression         Cleaned Text       0.826888   0.827765  0.826888   \n",
       "Support Vector Machines     Cleaned Text       0.825046   0.822884  0.825046   \n",
       "Multinomial Naive Bayes     Cleaned Text       0.804788   0.798024  0.804788   \n",
       "KNeighbors Classifier       Cleaned Text       0.723757   0.700185  0.723757   \n",
       "Decision Tree               Cleaned Text       0.799263   0.791885  0.799263   \n",
       "Random Forest               Cleaned Text       0.810313   0.823593  0.810313   \n",
       "Logistic Regression         Cleaned Text       0.771639   0.792641  0.771639   \n",
       "Support Vector Machines     Cleaned Text       0.769797   0.790767  0.769797   \n",
       "Multinomial Naive Bayes     Cleaned Text       0.749540   0.796832  0.749540   \n",
       "KNeighbors Classifier       Cleaned Text       0.758748   0.746820  0.758748   \n",
       "Decision Tree               Cleaned Text       0.720074   0.727385  0.720074   \n",
       "Random Forest               Cleaned Text       0.784530   0.775389  0.784530   \n",
       "Logistic Regression      Stematized Text       0.843462   0.845525  0.843462   \n",
       "Support Vector Machines  Stematized Text       0.841621   0.842081  0.841621   \n",
       "Multinomial Naive Bayes  Stematized Text       0.817680   0.811962  0.817680   \n",
       "KNeighbors Classifier    Stematized Text       0.712707   0.678187  0.712707   \n",
       "Decision Tree            Stematized Text       0.841621   0.837789  0.841621   \n",
       "Random Forest            Stematized Text       0.826888   0.840121  0.826888   \n",
       "Logistic Regression      Stematized Text       0.791897   0.811901  0.791897   \n",
       "Support Vector Machines  Stematized Text       0.791897   0.814893  0.791897   \n",
       "Multinomial Naive Bayes  Stematized Text       0.753223   0.800104  0.753223   \n",
       "KNeighbors Classifier    Stematized Text       0.764273   0.753502  0.764273   \n",
       "Decision Tree            Stematized Text       0.823204   0.818222  0.823204   \n",
       "Random Forest            Stematized Text       0.817680   0.823509  0.817680   \n",
       "Logistic Regression      Lemmatized Text       0.839779   0.843037  0.839779   \n",
       "Support Vector Machines  Lemmatized Text       0.843462   0.846482  0.843462   \n",
       "Multinomial Naive Bayes  Lemmatized Text       0.801105   0.793621  0.801105   \n",
       "KNeighbors Classifier    Lemmatized Text       0.718232   0.688574  0.718232   \n",
       "Decision Tree            Lemmatized Text       0.804788   0.797957  0.804788   \n",
       "Random Forest            Lemmatized Text       0.821363   0.837467  0.821363   \n",
       "Logistic Regression      Lemmatized Text       0.782689   0.803408  0.782689   \n",
       "Support Vector Machines  Lemmatized Text       0.780847   0.801663  0.780847   \n",
       "Multinomial Naive Bayes  Lemmatized Text       0.753223   0.800104  0.753223   \n",
       "KNeighbors Classifier    Lemmatized Text       0.769797   0.758439  0.769797   \n",
       "Decision Tree            Lemmatized Text       0.799263   0.793448  0.799263   \n",
       "Random Forest            Lemmatized Text       0.791897   0.792461  0.791897   \n",
       "\n",
       "                         F1-score  LR__C count_vec__binary  \\\n",
       "Logistic Regression      0.813534    1.0              True   \n",
       "Support Vector Machines  0.813627    NaN              True   \n",
       "Multinomial Naive Bayes  0.798526    NaN              True   \n",
       "KNeighbors Classifier    0.668487    NaN              True   \n",
       "Decision Tree            0.787444    NaN             False   \n",
       "Random Forest            0.786100    NaN              True   \n",
       "Logistic Regression      0.727352    1.0               NaN   \n",
       "Support Vector Machines  0.724450    NaN               NaN   \n",
       "Multinomial Naive Bayes  0.681934    NaN               NaN   \n",
       "KNeighbors Classifier    0.748783    NaN               NaN   \n",
       "Decision Tree            0.723251    NaN               NaN   \n",
       "Random Forest            0.769029    NaN               NaN   \n",
       "Logistic Regression      0.832728    1.0              True   \n",
       "Support Vector Machines  0.831540    NaN              True   \n",
       "Multinomial Naive Bayes  0.812060    NaN              True   \n",
       "KNeighbors Classifier    0.662052    NaN              True   \n",
       "Decision Tree            0.838074    NaN              True   \n",
       "Random Forest            0.807480    NaN              True   \n",
       "Logistic Regression      0.758078    1.0               NaN   \n",
       "Support Vector Machines  0.756948    NaN               NaN   \n",
       "Multinomial Naive Bayes  0.688522    NaN               NaN   \n",
       "KNeighbors Classifier    0.755488    NaN               NaN   \n",
       "Decision Tree            0.818832    NaN               NaN   \n",
       "Random Forest            0.799137    NaN               NaN   \n",
       "Logistic Regression      0.827700    1.0              True   \n",
       "Support Vector Machines  0.832200    NaN              True   \n",
       "Multinomial Naive Bayes  0.790906    NaN              True   \n",
       "KNeighbors Classifier    0.664438    NaN              True   \n",
       "Decision Tree            0.794194    NaN              True   \n",
       "Random Forest            0.799375    NaN             False   \n",
       "Logistic Regression      0.744373    1.0               NaN   \n",
       "Support Vector Machines  0.741581    NaN               NaN   \n",
       "Multinomial Naive Bayes  0.688522    NaN               NaN   \n",
       "KNeighbors Classifier    0.758999    NaN               NaN   \n",
       "Decision Tree            0.794999    NaN               NaN   \n",
       "Random Forest            0.768120    NaN               NaN   \n",
       "\n",
       "                        count_vec__ngram_range count_vec__stop_words  SVC__C  \\\n",
       "Logistic Regression                     (1, 1)                  None     NaN   \n",
       "Support Vector Machines                 (1, 1)                  None     0.1   \n",
       "Multinomial Naive Bayes                 (1, 1)               english     NaN   \n",
       "KNeighbors Classifier                   (1, 1)                  None     NaN   \n",
       "Decision Tree                           (1, 2)                  None     NaN   \n",
       "Random Forest                           (1, 1)                  None     NaN   \n",
       "Logistic Regression                        NaN                   NaN     NaN   \n",
       "Support Vector Machines                    NaN                   NaN     0.1   \n",
       "Multinomial Naive Bayes                    NaN                   NaN     NaN   \n",
       "KNeighbors Classifier                      NaN                   NaN     NaN   \n",
       "Decision Tree                              NaN                   NaN     NaN   \n",
       "Random Forest                              NaN                   NaN     NaN   \n",
       "Logistic Regression                     (1, 1)                  None     NaN   \n",
       "Support Vector Machines                 (1, 1)                  None     0.1   \n",
       "Multinomial Naive Bayes                 (1, 1)               english     NaN   \n",
       "KNeighbors Classifier                   (1, 1)                  None     NaN   \n",
       "Decision Tree                           (1, 1)                  None     NaN   \n",
       "Random Forest                           (1, 1)                  None     NaN   \n",
       "Logistic Regression                        NaN                   NaN     NaN   \n",
       "Support Vector Machines                    NaN                   NaN     0.1   \n",
       "Multinomial Naive Bayes                    NaN                   NaN     NaN   \n",
       "KNeighbors Classifier                      NaN                   NaN     NaN   \n",
       "Decision Tree                              NaN                   NaN     NaN   \n",
       "Random Forest                              NaN                   NaN     NaN   \n",
       "Logistic Regression                     (1, 1)                  None     NaN   \n",
       "Support Vector Machines                 (1, 1)                  None     0.1   \n",
       "Multinomial Naive Bayes                 (1, 2)               english     NaN   \n",
       "KNeighbors Classifier                   (1, 1)                  None     NaN   \n",
       "Decision Tree                           (1, 2)                  None     NaN   \n",
       "Random Forest                           (1, 1)                  None     NaN   \n",
       "Logistic Regression                        NaN                   NaN     NaN   \n",
       "Support Vector Machines                    NaN                   NaN     0.1   \n",
       "Multinomial Naive Bayes                    NaN                   NaN     NaN   \n",
       "KNeighbors Classifier                      NaN                   NaN     NaN   \n",
       "Decision Tree                              NaN                   NaN     NaN   \n",
       "Random Forest                              NaN                   NaN     NaN   \n",
       "\n",
       "                        tfidf__ngram_range tfidf__stop_words  \n",
       "Logistic Regression                    NaN               NaN  \n",
       "Support Vector Machines                NaN               NaN  \n",
       "Multinomial Naive Bayes                NaN               NaN  \n",
       "KNeighbors Classifier                  NaN               NaN  \n",
       "Decision Tree                          NaN               NaN  \n",
       "Random Forest                          NaN               NaN  \n",
       "Logistic Regression                 (1, 1)           english  \n",
       "Support Vector Machines             (1, 1)           english  \n",
       "Multinomial Naive Bayes             (1, 1)           english  \n",
       "KNeighbors Classifier               (1, 1)              None  \n",
       "Decision Tree                       (1, 1)           english  \n",
       "Random Forest                       (1, 1)           english  \n",
       "Logistic Regression                    NaN               NaN  \n",
       "Support Vector Machines                NaN               NaN  \n",
       "Multinomial Naive Bayes                NaN               NaN  \n",
       "KNeighbors Classifier                  NaN               NaN  \n",
       "Decision Tree                          NaN               NaN  \n",
       "Random Forest                          NaN               NaN  \n",
       "Logistic Regression                 (1, 1)              None  \n",
       "Support Vector Machines             (1, 1)              None  \n",
       "Multinomial Naive Bayes             (1, 1)           english  \n",
       "KNeighbors Classifier               (1, 1)              None  \n",
       "Decision Tree                       (1, 1)              None  \n",
       "Random Forest                       (1, 1)              None  \n",
       "Logistic Regression                    NaN               NaN  \n",
       "Support Vector Machines                NaN               NaN  \n",
       "Multinomial Naive Bayes                NaN               NaN  \n",
       "KNeighbors Classifier                  NaN               NaN  \n",
       "Decision Tree                          NaN               NaN  \n",
       "Random Forest                          NaN               NaN  \n",
       "Logistic Regression                 (1, 1)              None  \n",
       "Support Vector Machines             (1, 1)              None  \n",
       "Multinomial Naive Bayes             (1, 1)           english  \n",
       "KNeighbors Classifier               (1, 1)              None  \n",
       "Decision Tree                       (1, 1)              None  \n",
       "Random Forest                       (1, 1)              None  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f64261d5-0b39-4c25-a61b-e54c46acc3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalization</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LR__C</th>\n",
       "      <th>count_vec__binary</th>\n",
       "      <th>count_vec__ngram_range</th>\n",
       "      <th>count_vec__stop_words</th>\n",
       "      <th>SVC__C</th>\n",
       "      <th>tfidf__ngram_range</th>\n",
       "      <th>tfidf__stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.838074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.845525</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.832728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Stematized Text</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.842081</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.831540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Lemmatized Text</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.843037</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.827700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Normalization  Test Accuracy  Precision    Recall  \\\n",
       "Decision Tree            Stematized Text       0.841621   0.837789  0.841621   \n",
       "Logistic Regression      Stematized Text       0.843462   0.845525  0.843462   \n",
       "Support Vector Machines  Lemmatized Text       0.843462   0.846482  0.843462   \n",
       "Support Vector Machines  Stematized Text       0.841621   0.842081  0.841621   \n",
       "Logistic Regression      Lemmatized Text       0.839779   0.843037  0.839779   \n",
       "\n",
       "                         F1-score  LR__C count_vec__binary  \\\n",
       "Decision Tree            0.838074    NaN              True   \n",
       "Logistic Regression      0.832728    1.0              True   \n",
       "Support Vector Machines  0.832200    NaN              True   \n",
       "Support Vector Machines  0.831540    NaN              True   \n",
       "Logistic Regression      0.827700    1.0              True   \n",
       "\n",
       "                        count_vec__ngram_range count_vec__stop_words  SVC__C  \\\n",
       "Decision Tree                           (1, 1)                  None     NaN   \n",
       "Logistic Regression                     (1, 1)                  None     NaN   \n",
       "Support Vector Machines                 (1, 1)                  None     0.1   \n",
       "Support Vector Machines                 (1, 1)                  None     0.1   \n",
       "Logistic Regression                     (1, 1)                  None     NaN   \n",
       "\n",
       "                        tfidf__ngram_range tfidf__stop_words  \n",
       "Decision Tree                          NaN               NaN  \n",
       "Logistic Regression                    NaN               NaN  \n",
       "Support Vector Machines                NaN               NaN  \n",
       "Support Vector Machines                NaN               NaN  \n",
       "Logistic Regression                    NaN               NaN  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('F1-score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4eaf9b-5714-40cb-9366-685854edac56",
   "metadata": {},
   "source": [
    "O **Decision Tree** foi selecionado como o modelo final. Ele será aplicado ao texto após o processo de stemização. A representação binária, utilizando unigramas e incluindo stopwords, será adotada para a construção desse modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ee8396-c101-4a7b-9d02-59941d3679a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/cv.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "count_vec = CountVectorizer(binary=True)\n",
    "\n",
    "X = df.stematized_text\n",
    "y = df.encoded_sentiment\n",
    "\n",
    "X_vec = count_vec.fit_transform(X)\n",
    "\n",
    "dt.fit(X_vec, y)\n",
    "\n",
    "dump(dt, f'../{cfg.models.dt}')\n",
    "dump(count_vec, f'../{cfg.models.cv}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
